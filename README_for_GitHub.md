# ğŸš€ SVM+HOG vs CNN Image Classification Comparison

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yourusername/your-exam-repo/blob/main/SVM_vs_CNN_Image_Classification_Comparison.ipynb)

A comprehensive comparison between traditional computer vision (SVM + HOG) and deep learning (CNN) approaches for image classification.

## ğŸ¯ Overview

This project implements and compares two different image classification methodologies:
- **SVM + HOG**: Traditional computer vision approach using Histogram of Oriented Gradients features with Support Vector Machine
- **CNN**: Deep learning approach using Convolutional Neural Networks with data augmentation

## ğŸ“Š Features

- ğŸ” **Automatic GPU Detection**: Utilizes GPU acceleration when available
- ğŸ“ˆ **Comprehensive Analysis**: Accuracy, training time, and inference speed comparison
- ğŸ¨ **Rich Visualizations**: Performance charts, confusion matrices, and detailed metrics
- ğŸ“¥ **Separate Downloads**: Models, results, dataset, and configurations
- âš™ï¸ **Configurable Parameters**: Easy hyperparameter tuning for both approaches
- ğŸ§ª **Reproducible Results**: Consistent random seeds and detailed documentation

## ğŸ—‚ï¸ Dataset

The project includes a synthetic dataset with three classes:
- **Normal**: Blue-ish images with noise patterns
- **Cheating**: Red-ish images with diagonal line patterns  
- **Looking Around**: Green-ish images with circular patterns

**Dataset Statistics:**
- ğŸ“Š **Classes**: 3
- ğŸ–¼ï¸ **Images**: 150 total (50 per class)
- ğŸ“ **Size**: 128x128 pixels
- ğŸ¨ **Format**: PNG images
- ğŸ”€ **Split**: 80% training, 20% testing

## ğŸš€ Quick Start

### Option 1: Google Colab (Recommended)
1. Click the "Open in Colab" badge above
2. Run all cells in sequence
3. Download results using the provided download cells

### Option 2: Local Setup
```bash
# Clone the repository
git clone https://github.com/yourusername/your-exam-repo.git
cd your-exam-repo

# Install dependencies
pip install -r requirements.txt

# Run the comparison
python main.py --data_dir dataset
```

## ğŸ“‹ Requirements

### For Google Colab
All dependencies are automatically installed in the notebook.

### For Local Setup
```
numpy==1.24.3
opencv-python==4.8.1.78
scikit-learn==1.3.0
tensorflow==2.13.0
matplotlib==3.7.2
seaborn==0.12.2
Pillow==10.0.0
scikit-image==0.21.0
tqdm==4.66.1
```

## ğŸ—ï¸ Architecture

### SVM + HOG Model
- **Feature Extraction**: Histogram of Oriented Gradients (HOG)
- **Classification**: Support Vector Machine with RBF kernel
- **Preprocessing**: Standard scaling of features
- **Advantages**: Fast training, interpretable features, good with small datasets

### CNN Model
- **Architecture**: 3 convolutional layers + 2 dense layers
- **Optimization**: Adam optimizer with early stopping
- **Augmentation**: Rotation, shifting, shearing, zooming, flipping
- **Advantages**: High accuracy potential, automatic feature learning

## ğŸ“ˆ Results

### Expected Performance Characteristics
- **SVM + HOG**: 
  - âœ… Faster training time
  - âœ… Faster inference speed
  - âœ… Lower memory usage
  - âš ï¸ May have lower accuracy on complex patterns

- **CNN**: 
  - âœ… Higher accuracy potential
  - âœ… Better scalability
  - âœ… Automatic feature learning
  - âš ï¸ Longer training time
  - âš ï¸ Higher computational requirements

## ğŸ“ Project Structure

```
your-exam-repo/
â”œâ”€â”€ SVM_vs_CNN_Image_Classification_Comparison.ipynb  # Main Colab notebook
â”œâ”€â”€ dataset/                                          # Image dataset
â”‚   â”œâ”€â”€ normal/
â”‚   â”‚   â”œâ”€â”€ normal_001.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ cheating/
â”‚   â”‚   â”œâ”€â”€ cheating_001.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ looking_around/
â”‚       â”œâ”€â”€ looking_around_001.png
â”‚       â””â”€â”€ ...
â”œâ”€â”€ results/                                          # Generated results
â”‚   â”œâ”€â”€ model_comparison.json
â”‚   â”œâ”€â”€ accuracy_comparison.png
â”‚   â”œâ”€â”€ training_time_comparison.png
â”‚   â”œâ”€â”€ inference_time_comparison.png
â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â””â”€â”€ detailed_metrics.png
â”œâ”€â”€ README.md                                         # This file
â””â”€â”€ requirements.txt                                  # Dependencies
```

## âš™ï¸ Configuration

Both models can be easily configured by modifying the configuration dictionaries in the notebook:

### SVM + HOG Configuration
```python
SVM_HOG_CONFIG = {
    'hog_params': {
        'orientations': 9,
        'pixels_per_cell': (8, 8),
        'cells_per_block': (2, 2),
    },
    'svm_params': {
        'C': 1.0,
        'kernel': 'rbf',
        'gamma': 'scale',
    }
}
```

### CNN Configuration
```python
CNN_CONFIG = {
    'training': {
        'epochs': 50,
        'batch_size': 32,
        'learning_rate': 0.001,
    },
    'architecture': {
        'conv_layers': [
            {'filters': 32, 'kernel_size': (3, 3)},
            {'filters': 64, 'kernel_size': (3, 3)},
            {'filters': 128, 'kernel_size': (3, 3)},
        ]
    }
}
```

## ğŸ“Š Evaluation Metrics

The comparison includes:
- **Accuracy**: Overall and per-class performance
- **Training Time**: Model training duration
- **Inference Speed**: Prediction time per sample
- **Confusion Matrices**: Error analysis
- **Precision, Recall, F1-Score**: Detailed performance metrics

## ğŸ“¥ Downloads

The notebook provides separate download packages for:
1. **Results Package**: JSON reports and performance metrics
2. **Models Package**: Trained SVM and CNN models
3. **Dataset Package**: Complete image dataset
4. **Configuration Package**: All hyperparameter settings

## ğŸ”§ Customization

### Using Your Own Dataset
1. Organize your images in subdirectories by class
2. Update the `dataset_dir` path in the notebook
3. Ensure images are in supported formats (PNG, JPG)
4. Run the notebook to train and compare models

### Modifying Model Architectures
- **SVM**: Adjust kernel type, C parameter, gamma in config
- **CNN**: Modify layer configurations, add/remove layers
- **Augmentation**: Customize data augmentation parameters

## ğŸ® GPU Acceleration

The notebook automatically detects and configures GPU usage:
- **Automatic Detection**: Checks for available GPUs
- **Memory Growth**: Enables dynamic GPU memory allocation
- **Mixed Precision**: Uses float16 for better performance when available
- **Fallback**: Gracefully falls back to CPU if no GPU is available

## ğŸ› Troubleshooting

### Common Issues

1. **Out of Memory (GPU)**
   - Reduce batch size in CNN config
   - Reduce image size in dataset config

2. **Long Training Times**
   - Use GPU acceleration
   - Reduce number of epochs for testing
   - Use smaller dataset for initial experiments

3. **Import Errors**
   - Ensure all dependencies are installed
   - Use Google Colab for automatic dependency management

## ğŸ“š Educational Value

This project demonstrates:
- **Traditional vs Modern Approaches**: SVM+HOG vs CNN comparison
- **Feature Engineering**: Manual (HOG) vs automatic (CNN) feature extraction
- **Performance Trade-offs**: Accuracy vs speed vs computational requirements
- **Best Practices**: Proper evaluation, visualization, and reproducibility

## ğŸ¤ Contributing

Feel free to contribute by:
- Adding new model architectures
- Improving visualizations
- Adding new evaluation metrics
- Optimizing performance
- Enhancing documentation

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ¯ Academic Use

Perfect for:
- Machine Learning coursework
- Computer Vision projects
- Algorithm comparison studies
- Research demonstrations
- Educational presentations

## ğŸ“ Support

If you encounter any issues:
1. Check the troubleshooting section above
2. Review the notebook comments and documentation
3. Open an issue in the repository
4. Refer to the TensorFlow and scikit-learn documentation

---

**ğŸ‰ Happy Learning and Experimenting!**

*This project showcases the evolution from traditional computer vision to deep learning approaches, providing hands-on experience with both methodologies.*