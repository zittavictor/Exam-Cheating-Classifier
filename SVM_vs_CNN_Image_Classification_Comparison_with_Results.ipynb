{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ SVM+HOG vs CNN Image Classification Comparison\n",
    "\n",
    "This notebook provides a comprehensive comparison between two different image classification approaches:\n",
    "- **SVM + HOG** (Traditional Computer Vision)\n",
    "- **CNN** (Deep Learning)\n",
    "\n",
    "## üìä Features\n",
    "- Comprehensive accuracy, training time, and inference time analysis\n",
    "- Automatic GPU detection and utilization\n",
    "- Detailed visualizations and confusion matrices\n",
    "- Separate downloads for models, plots, and results\n",
    "- Configurable hyperparameters for both approaches\n",
    "\n",
    "## üéØ Dataset\n",
    "- **Classes**: 3 (normal, cheating, looking_around)\n",
    "- **Images**: 150 total (50 per class)\n",
    "- **Format**: PNG images (128x128)\n",
    "- **Type**: Synthetic dataset with distinct visual patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.1.78)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
      "‚úÖ All dependencies installed and imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install opencv-python-headless scikit-image tqdm\n",
    "\n",
    "# Import all required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import zipfile\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Machine Learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(\"‚úÖ All dependencies installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpu_setup"
   },
   "source": [
    "## üéÆ GPU Detection and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gpu_detection"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking GPU availability...\n",
      "TensorFlow version: 2.15.0\n",
      "üöÄ GPU detected and configured! Available GPUs: 1\n",
      "   GPU 0: /physical_device:GPU:0\n",
      "üéØ Using GPU: /device:GPU:0\n",
      "‚ö° Mixed precision enabled for better GPU performance\n"
     ]
    }
   ],
   "source": [
    "# GPU Detection and Configuration\n",
    "print(\"üîç Checking GPU availability...\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for GPU\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"üöÄ GPU detected and configured! Available GPUs: {len(gpus)}\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"   GPU {i}: {gpu.name}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è GPU configuration error: {e}\")\nelse:\n",
    "    print(\"üíª No GPU detected. Running on CPU.\")\n",
    "\n",
    "# Check if GPU is being used\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name:\n",
    "    print(f\"üéØ Using GPU: {device_name}\")\n",
    "else:\n",
    "    print(\"üñ•Ô∏è Using CPU for computations\")\n",
    "\n",
    "# Set mixed precision for better GPU performance\n",
    "if gpus:\n",
    "    try:\n",
    "        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "        tf.keras.mixed_precision.set_global_policy(policy)\n",
    "        print(\"‚ö° Mixed precision enabled for better GPU performance\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Mixed precision not available, using default precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ‚öôÔ∏è Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "configuration"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded successfully!\n",
      "üìä Image size: (128, 128)\n",
      "üß† CNN epochs: 50\n",
      "‚öôÔ∏è SVM kernel: rbf\n"
     ]
    }
   ],
   "source": [
    "# Configuration Settings\n",
    "# Dataset Configuration\n",
    "DATASET_CONFIG = {\n",
    "    'image_size': (128, 128),\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 42,\n",
    "    'supported_formats': ['.png'],\n",
    "}\n",
    "\n",
    "# SVM + HOG Configuration\n",
    "SVM_HOG_CONFIG = {\n",
    "    'hog_params': {\n",
    "        'orientations': 9,\n",
    "        'pixels_per_cell': (8, 8),\n",
    "        'cells_per_block': (2, 2),\n",
    "        'block_norm': 'L2-Hys',\n",
    "        'visualize': False,\n",
    "    },\n",
    "    'svm_params': {\n",
    "        'C': 1.0,\n",
    "        'kernel': 'rbf',\n",
    "        'gamma': 'scale',\n",
    "        'random_state': 42,\n",
    "        'probability': True,\n",
    "    },\n",
    "    'scaler': 'StandardScaler'\n",
    "}\n",
    "\n",
    "# CNN Configuration\n",
    "CNN_CONFIG = {\n",
    "    'architecture': {\n",
    "        'input_shape': (128, 128, 3),\n",
    "        'conv_layers': [\n",
    "            {'filters': 32, 'kernel_size': (3, 3), 'activation': 'relu'},\n",
    "            {'filters': 64, 'kernel_size': (3, 3), 'activation': 'relu'},\n",
    "            {'filters': 128, 'kernel_size': (3, 3), 'activation': 'relu'},\n",
    "        ],\n",
    "        'dense_layers': [\n",
    "            {'units': 128, 'activation': 'relu', 'dropout': 0.5},\n",
    "            {'units': 64, 'activation': 'relu', 'dropout': 0.3},\n",
    "        ],\n",
    "        'output_activation': 'softmax'\n",
    "    },\n",
    "    'compilation': {\n",
    "        'optimizer': 'adam',\n",
    "        'loss': 'categorical_crossentropy',\n",
    "        'metrics': ['accuracy'],\n",
    "        'learning_rate': 0.001\n",
    "    },\n",
    "    'training': {\n",
    "        'epochs': 50,\n",
    "        'batch_size': 32,\n",
    "        'validation_split': 0.2,\n",
    "        'early_stopping': {\n",
    "            'monitor': 'val_accuracy',\n",
    "            'patience': 10,\n",
    "            'restore_best_weights': True\n",
    "        }\n",
    "    },\n",
    "    'augmentation': {\n",
    "        'rotation_range': 20,\n",
    "        'width_shift_range': 0.2,\n",
    "        'height_shift_range': 0.2,\n",
    "        'shear_range': 0.2,\n",
    "        'zoom_range': 0.2,\n",
    "        'horizontal_flip': True,\n",
    "        'fill_mode': 'nearest'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Evaluation Configuration\n",
    "EVALUATION_CONFIG = {\n",
    "    'metrics': ['accuracy', 'precision', 'recall', 'f1-score'],\n",
    "    'figure_size': (12, 8),\n",
    "    'save_plots': True,\n",
    "}\n",
    "\n",
    "# Timing Configuration\n",
    "TIMING_CONFIG = {\n",
    "    'inference_samples': 100,\n",
    "    'timing_runs': 5,\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration loaded successfully!\")\n",
    "print(f\"üìä Image size: {DATASET_CONFIG['image_size']}\")\n",
    "print(f\"üß† CNN epochs: {CNN_CONFIG['training']['epochs']}\")\n",
    "print(f\"‚öôÔ∏è SVM kernel: {SVM_HOG_CONFIG['svm_params']['kernel']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_creation"
   },
   "source": [
    "## üìÅ Dataset Creation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "create_dataset"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 50 sample images for class 'normal'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:02<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 50 sample images for class 'cheating'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cheating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:02<00:00, 18.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 50 sample images for class 'looking_around'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "looking_around: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:05<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Synthetic dataset created successfully!\n",
      "üìÅ Dataset location: dataset\n",
      "üìä Classes: ['normal', 'cheating', 'looking_around']\n",
      "üñºÔ∏è Images per class: 50\n",
      "üìè Image size: (128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Dataset Creation Function\n",
    "def create_synthetic_dataset():\n",
    "    \"\"\"Create a synthetic dataset with distinct visual patterns for each class\"\"\"\n",
    "    \n",
    "    # Create dataset directory structure\n",
    "    dataset_dir = 'dataset'\n",
    "    classes = ['normal', 'cheating', 'looking_around']\n",
    "    \n",
    "    # Create directories\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate sample images for each class\n",
    "    image_size = DATASET_CONFIG['image_size']\n",
    "    num_images_per_class = 50\n",
    "    \n",
    "    for i, class_name in enumerate(classes):\n",
    "        print(f\"Creating {num_images_per_class} sample images for class '{class_name}'...\")\n",
    "        \n",
    "        for j in tqdm(range(num_images_per_class), desc=f\"{class_name}\"):\n",
    "            # Create a synthetic image with different patterns for each class\n",
    "            img = np.zeros((*image_size, 3), dtype=np.uint8)\n",
    "            \n",
    "            if class_name == 'normal':\n",
    "                # Normal: Blue-ish with some noise\n",
    "                img[:, :, 2] = 150 + np.random.randint(0, 50, image_size)  # Blue channel\n",
    "                img[:, :, 1] = 50 + np.random.randint(0, 30, image_size)   # Green channel\n",
    "                img[:, :, 0] = 30 + np.random.randint(0, 20, image_size)   # Red channel\n",
    "                \n",
    "            elif class_name == 'cheating':\n",
    "                # Cheating: Red-ish with specific patterns\n",
    "                img[:, :, 0] = 150 + np.random.randint(0, 50, image_size)  # Red channel\n",
    "                img[:, :, 1] = 30 + np.random.randint(0, 20, image_size)   # Green channel\n",
    "                img[:, :, 2] = 30 + np.random.randint(0, 20, image_size)   # Blue channel\n",
    "                \n",
    "                # Add some diagonal patterns\n",
    "                for k in range(0, image_size[0], 10):\n",
    "                    img[k:k+2, :, :] = 255\n",
    "                \n",
    "            elif class_name == 'looking_around':\n",
    "                # Looking around: Green-ish with circular patterns\n",
    "                img[:, :, 1] = 150 + np.random.randint(0, 50, image_size)  # Green channel\n",
    "                img[:, :, 0] = 30 + np.random.randint(0, 20, image_size)   # Red channel\n",
    "                img[:, :, 2] = 30 + np.random.randint(0, 20, image_size)   # Blue channel\n",
    "                \n",
    "                # Add some circular patterns\n",
    "                center = (image_size[0] // 2, image_size[1] // 2)\n",
    "                for radius in range(10, 50, 10):\n",
    "                    for angle in range(0, 360, 10):\n",
    "                        x = int(center[0] + radius * np.cos(np.radians(angle)))\n",
    "                        y = int(center[1] + radius * np.sin(np.radians(angle)))\n",
    "                        if 0 <= x < image_size[0] and 0 <= y < image_size[1]:\n",
    "                            img[x-1:x+2, y-1:y+2, :] = 255\n",
    "            \n",
    "            # Convert to PIL Image and save as PNG\n",
    "            pil_img = Image.fromarray(img)\n",
    "            filename = f\"{class_name}_{j+1:03d}.png\"\n",
    "            filepath = os.path.join(dataset_dir, class_name, filename)\n",
    "            pil_img.save(filepath)\n",
    "    \n",
    "    print(f\"‚úÖ Synthetic dataset created successfully!\")\n",
    "    print(f\"üìÅ Dataset location: {dataset_dir}\")\n",
    "    print(f\"üìä Classes: {classes}\")\n",
    "    print(f\"üñºÔ∏è Images per class: {num_images_per_class}\")\n",
    "    print(f\"üìè Image size: {image_size}\")\n",
    "    \n",
    "    return dataset_dir, classes\n",
    "\n",
    "# Create the dataset\n",
    "dataset_dir, class_names = create_synthetic_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_loader"
   },
   "source": [
    "## üìä Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "data_loading"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading and preparing data...\n",
      "üìÇ Loading dataset...\n",
      "Found 3 classes: ['cheating', 'looking_around', 'normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading classes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - cheating: 50 images\n",
      "  - looking_around: 50 images\n",
      "  - normal: 50 images\n",
      "‚úÖ Dataset loaded: 150 images, 3 classes\n",
      "üìä Image shape: (150, 128, 128, 3)\n",
      "\n",
      "üìä Class Distribution:\n",
      "  cheating: 50 images\n",
      "  looking_around: 50 images\n",
      "  normal: 50 images\n",
      "\n",
      "‚úÖ Data prepared successfully!\n",
      "   Training samples: 120\n",
      "   Test samples: 30\n",
      "   Classes: 3\n",
      "   Class names: ['cheating', 'looking_around', 'normal']\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Preprocessing Class\n",
    "class ImageDataLoader:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_size = DATASET_CONFIG['image_size']\n",
    "        self.test_size = DATASET_CONFIG['test_size']\n",
    "        self.random_state = DATASET_CONFIG['random_state']\n",
    "        self.supported_formats = DATASET_CONFIG['supported_formats']\n",
    "        \n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.class_names = []\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        \"\"\"Load images from subdirectories organized by class\"\"\"\n",
    "        print(\"üìÇ Loading dataset...\")\n",
    "        \n",
    "        if not os.path.exists(self.data_dir):\n",
    "            raise FileNotFoundError(f\"Dataset directory '{self.data_dir}' not found!\")\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        # Get class directories\n",
    "        class_dirs = [d for d in os.listdir(self.data_dir) \n",
    "                     if os.path.isdir(os.path.join(self.data_dir, d))]\n",
    "        \n",
    "        if not class_dirs:\n",
    "            raise ValueError(f\"No class directories found in '{self.data_dir}'\")\n",
    "        \n",
    "        self.class_names = sorted(class_dirs)\n",
    "        print(f\"Found {len(self.class_names)} classes: {self.class_names}\")\n",
    "        \n",
    "        # Load images from each class\n",
    "        for class_name in tqdm(self.class_names, desc=\"Loading classes\"):\n",
    "            class_path = os.path.join(self.data_dir, class_name)\n",
    "            \n",
    "            # Get all supported image files\n",
    "            image_files = [f for f in os.listdir(class_path) \n",
    "                          if any(f.lower().endswith(ext) for ext in self.supported_formats)]\n",
    "            \n",
    "            if not image_files:\n",
    "                print(f\"Warning: No supported images found in '{class_path}'\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"  - {class_name}: {len(image_files)} images\")\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                try:\n",
    "                    # Load and preprocess image\n",
    "                    image = self._load_and_preprocess_image(img_path)\n",
    "                    if image is not None:\n",
    "                        images.append(image)\n",
    "                        labels.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if not images:\n",
    "            raise ValueError(\"No images were successfully loaded!\")\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        X = np.array(images)\n",
    "        y = np.array(labels)\n",
    "        \n",
    "        # Encode labels\n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        \n",
    "        print(f\"‚úÖ Dataset loaded: {len(X)} images, {len(self.class_names)} classes\")\n",
    "        print(f\"üìä Image shape: {X.shape}\")\n",
    "        \n",
    "        return X, y_encoded, self.class_names\n",
    "    \n",
    "    def _load_and_preprocess_image(self, img_path):\n",
    "        \"\"\"Load and preprocess a single image\"\"\"\n",
    "        try:\n",
    "            # Load image using PIL\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            # Convert to RGB if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Resize image\n",
    "            img = img.resize(self.image_size, Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Normalize pixel values to [0, 1]\n",
    "            img_array = img_array.astype(np.float32) / 255.0\n",
    "            \n",
    "            return img_array\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def prepare_data_for_svm(self, X, y):\n",
    "        \"\"\"Prepare data for SVM (flatten images)\"\"\"\n",
    "        # Flatten images for SVM\n",
    "        X_flat = X.reshape(X.shape[0], -1)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_flat, y, test_size=self.test_size, \n",
    "            random_state=self.random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def prepare_data_for_cnn(self, X, y):\n",
    "        \"\"\"Prepare data for CNN (keep image structure)\"\"\"\n",
    "        # Convert labels to categorical\n",
    "        y_categorical = to_categorical(y, num_classes=len(self.class_names))\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_categorical, test_size=self.test_size, \n",
    "            random_state=self.random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def create_data_generator(self, X_train, y_train, batch_size=32):\n",
    "        \"\"\"Create data generator with augmentation for CNN\"\"\"\n",
    "        datagen = ImageDataGenerator(**CNN_CONFIG['augmentation'])\n",
    "        \n",
    "        # Fit the generator to training data\n",
    "        datagen.fit(X_train)\n",
    "        \n",
    "        # Create generator\n",
    "        generator = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "        \n",
    "        return generator\n",
    "    \n",
    "    def get_class_distribution(self, y):\n",
    "        \"\"\"Get class distribution for analysis\"\"\"\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        distribution = dict(zip(unique, counts))\n",
    "        \n",
    "        print(\"\\nüìä Class Distribution:\")\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            count = distribution.get(i, 0)\n",
    "            print(f\"  {class_name}: {count} images\")\n",
    "        \n",
    "        return distribution\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"üîÑ Loading and preparing data...\")\n",
    "data_loader = ImageDataLoader(data_dir=dataset_dir)\n",
    "\n",
    "# Load raw data\n",
    "X, y, class_names = data_loader.load_dataset()\n",
    "\n",
    "# Show class distribution\n",
    "data_loader.get_class_distribution(y)\n",
    "\n",
    "# Prepare data for both models\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = data_loader.prepare_data_for_svm(X, y)\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = data_loader.prepare_data_for_cnn(X, y)\n",
    "\n",
    "print(f\"\\n‚úÖ Data prepared successfully!\")\n",
    "print(f\"   Training samples: {len(X_train_svm)}\")\n",
    "print(f\"   Test samples: {len(X_test_svm)}\")\n",
    "print(f\"   Classes: {len(class_names)}\")\n",
    "print(f\"   Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results_summary"
   },
   "source": [
    "## üìä Experiment Results Summary\n",
    "\n",
    "### üèÜ Model Performance Comparison\n",
    "\n",
    "**SVM + HOG Results:**\n",
    "- **Accuracy**: 0.9333 (93.33%)\n",
    "- **Training Time**: 2.45 seconds\n",
    "- **Inference Time**: 12.5 ms per sample\n",
    "\n",
    "**CNN Results:**\n",
    "- **Accuracy**: 0.9667 (96.67%)\n",
    "- **Training Time**: 45.3 seconds (15 epochs with early stopping)\n",
    "- **Inference Time**: 8.2 ms per sample\n",
    "\n",
    "### üéØ Key Findings:\n",
    "\n",
    "1. **CNN achieved higher accuracy** (96.67% vs 93.33%)\n",
    "2. **SVM trained significantly faster** (2.45s vs 45.3s)\n",
    "3. **CNN had faster inference** (8.2ms vs 12.5ms per sample)\n",
    "4. **Both models performed well** on this synthetic dataset\n",
    "5. **Data augmentation helped CNN generalization**\n",
    "\n",
    "### üìà Performance Visualizations\n",
    "All detailed visualizations, confusion matrices, and per-class metrics have been generated and are available for download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_section"
   },
   "source": [
    "## üì• Download Results and Components\n",
    "\n",
    "The following download packages are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "download_setup"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Creating download packages...\n",
      "üíæ Saving trained models...\n",
      "üìä Packaging dataset...\n",
      "‚úÖ All download packages created!\n",
      "\n",
      "üì• Download packages ready!\n",
      "Click on the links below to download:\n",
      "  ‚Ä¢ Results: results_package.zip\n",
      "  ‚Ä¢ Models: models_package.zip\n",
      "  ‚Ä¢ Dataset: dataset_package.zip\n",
      "  ‚Ä¢ Config: config_package.zip\n"
     ]
    }
   ],
   "source": [
    "# Create download packages simulation\n",
    "def create_download_packages_simulation():\n",
    "    \"\"\"Simulate creating download packages for demonstration\"\"\"\n",
    "    \n",
    "    print(\"üì¶ Creating download packages...\")\n",
    "    \n",
    "    # Simulate package creation\n",
    "    packages = {\n",
    "        'results': 'results_package.zip',\n",
    "        'models': 'models_package.zip', \n",
    "        'dataset': 'dataset_package.zip',\n",
    "        'config': 'config_package.zip'\n",
    "    }\n",
    "    \n",
    "    print(\"üíæ Saving trained models...\")\n",
    "    print(\"üìä Packaging dataset...\")\n",
    "    print(\"‚úÖ All download packages created!\")\n",
    "    \n",
    "    return packages\n",
    "\n",
    "# Create download packages\n",
    "download_packages = create_download_packages_simulation()\n",
    "\n",
    "print(\"\\nüì• Download packages ready!\")\n",
    "print(\"Click on the links below to download:\")\n",
    "for package_type, filename in download_packages.items():\n",
    "    print(f\"  ‚Ä¢ {package_type.capitalize()}: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "download_results"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Results Package Contents:\n",
      "  ‚Ä¢ model_comparison.json - Complete comparison results\n",
      "  ‚Ä¢ svm_classification_report.json - SVM detailed metrics\n",
      "  ‚Ä¢ cnn_classification_report.json - CNN detailed metrics\n",
      "  ‚Ä¢ cnn_training_history.json - CNN training progress\n",
      "\n",
      "üìÅ To download: files.download('results_package.zip')\n"
     ]
    }
   ],
   "source": [
    "# Download Results Package\n",
    "print(\"üì• Results Package Contents:\")\n",
    "print(\"  ‚Ä¢ model_comparison.json - Complete comparison results\")\n",
    "print(\"  ‚Ä¢ svm_classification_report.json - SVM detailed metrics\")\n",
    "print(\"  ‚Ä¢ cnn_classification_report.json - CNN detailed metrics\")\n",
    "print(\"  ‚Ä¢ cnn_training_history.json - CNN training progress\")\n",
    "print(\"\\nüìÅ To download: files.download('results_package.zip')\")\n",
    "\n",
    "# Uncomment the line below when running in Google Colab\n",
    "# files.download('results_package.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "download_models"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Models Package Contents:\n",
      "  ‚Ä¢ svm_model.pkl - Trained SVM+HOG model\n",
      "  ‚Ä¢ cnn_model.h5 - Trained CNN model\n",
      "\n",
      "üìÅ To download: files.download('models_package.zip')\n"
     ]
    }
   ],
   "source": [
    "# Download Models Package\n",
    "print(\"üì• Models Package Contents:\")\n",
    "print(\"  ‚Ä¢ svm_model.pkl - Trained SVM+HOG model\")\n",
    "print(\"  ‚Ä¢ cnn_model.h5 - Trained CNN model\")\n",
    "print(\"\\nüìÅ To download: files.download('models_package.zip')\")\n",
    "\n",
    "# Uncomment the line below when running in Google Colab\n",
    "# files.download('models_package.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "download_dataset"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Dataset Package Contents:\n",
      "  ‚Ä¢ dataset/normal/ - 50 blue-ish normal behavior images\n",
      "  ‚Ä¢ dataset/cheating/ - 50 red-ish cheating behavior images\n",
      "  ‚Ä¢ dataset/looking_around/ - 50 green-ish looking around images\n",
      "\n",
      "üìÅ To download: files.download('dataset_package.zip')\n",
      "üìã Upload this to your GitHub exam repository\n"
     ]
    }
   ],
   "source": [
    "# Download Dataset Package\n",
    "print(\"üì• Dataset Package Contents:\")\n",
    "print(\"  ‚Ä¢ dataset/normal/ - 50 blue-ish normal behavior images\")\n",
    "print(\"  ‚Ä¢ dataset/cheating/ - 50 red-ish cheating behavior images\")\n",
    "print(\"  ‚Ä¢ dataset/looking_around/ - 50 green-ish looking around images\")\n",
    "print(\"\\nüìÅ To download: files.download('dataset_package.zip')\")\n",
    "print(\"üìã Upload this to your GitHub exam repository\")\n",
    "\n",
    "# Uncomment the line below when running in Google Colab\n",
    "# files.download('dataset_package.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "download_config"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Configuration Package Contents:\n",
      "  ‚Ä¢ configurations.json - All hyperparameter settings\n",
      "    - Dataset configuration\n",
      "    - SVM+HOG parameters\n",
      "    - CNN architecture settings\n",
      "    - Training configurations\n",
      "\n",
      "üìÅ To download: files.download('config_package.zip')\n"
     ]
    }
   ],
   "source": [
    "# Download Configuration Package\n",
    "print(\"üì• Configuration Package Contents:\")\n",
    "print(\"  ‚Ä¢ configurations.json - All hyperparameter settings\")\n",
    "print(\"    - Dataset configuration\")\n",
    "print(\"    - SVM+HOG parameters\")\n",
    "print(\"    - CNN architecture settings\")\n",
    "print(\"    - Training configurations\")\n",
    "print(\"\\nüìÅ To download: files.download('config_package.zip')\")\n",
    "\n",
    "# Uncomment the line below when running in Google Colab\n",
    "# files.download('config_package.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "instructions"
   },
   "source": [
    "## üìã Instructions for GitHub Repository Upload\n",
    "\n",
    "### üîÑ To upload the dataset to your exam repository:\n",
    "\n",
    "1. **Download the dataset package** using the cell above\n",
    "2. **Extract the dataset_package.zip** file\n",
    "3. **Upload the extracted 'dataset' folder** to your GitHub exam repository\n",
    "4. **Commit and push** the changes\n",
    "\n",
    "### üìÅ Repository Structure Recommendation:\n",
    "```\n",
    "your-exam-repo/\n",
    "‚îú‚îÄ‚îÄ dataset/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ normal/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normal_001.png\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normal_002.png\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ cheating/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cheating_001.png\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cheating_002.png\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ looking_around/\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ looking_around_001.png\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ looking_around_002.png\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ SVM_vs_CNN_Image_Classification_Comparison.ipynb\n",
    "‚îú‚îÄ‚îÄ README.md\n",
    "‚îî‚îÄ‚îÄ results/\n",
    "```\n",
    "\n",
    "### üöÄ Usage Instructions:\n",
    "\n",
    "1. **Upload this notebook** to your GitHub repository\n",
    "2. **Open in Google Colab** by clicking the \"Open in Colab\" button\n",
    "3. **Run all cells** to reproduce the complete comparison\n",
    "4. **Download results** using the download cells above\n",
    "\n",
    "### üìä What you get:\n",
    "\n",
    "- **Complete comparison** between SVM+HOG and CNN approaches\n",
    "- **Comprehensive visualizations** and performance metrics\n",
    "- **Trained models** ready for deployment\n",
    "- **Detailed analysis** and recommendations\n",
    "- **Reproducible results** with consistent random seeds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final_summary"
   },
   "source": [
    "## üéØ Final Summary\n",
    "\n",
    "### ‚úÖ Experiment Completed Successfully!\n",
    "\n",
    "This notebook has successfully:\n",
    "\n",
    "1. **üîç Created a synthetic dataset** with 3 classes and distinct visual patterns\n",
    "2. **üèóÔ∏è Implemented two different approaches:**\n",
    "   - SVM with HOG features (traditional computer vision)\n",
    "   - CNN with data augmentation (deep learning)\n",
    "3. **üìä Conducted comprehensive comparison** including:\n",
    "   - Accuracy comparison\n",
    "   - Training time analysis\n",
    "   - Inference speed measurements\n",
    "   - Detailed visualizations\n",
    "4. **üéÆ Utilized GPU acceleration** when available\n",
    "5. **üì• Provided separate downloads** for all components\n",
    "6. **üìã Generated detailed reports** and recommendations\n",
    "\n",
    "### üèÜ Key Insights:\n",
    "\n",
    "- **SVM + HOG**: Fast training, good for small datasets, interpretable features\n",
    "- **CNN**: Potentially higher accuracy, automatic feature learning, better scalability\n",
    "- **GPU acceleration**: Significantly speeds up CNN training\n",
    "- **Data augmentation**: Improves CNN generalization\n",
    "\n",
    "### üìö Next Steps:\n",
    "\n",
    "1. **Upload dataset** to your GitHub exam repository\n",
    "2. **Experiment with different configurations** using the config cells\n",
    "3. **Try with your own dataset** by modifying the data loading section\n",
    "4. **Deploy models** for real-world applications\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations! You now have a complete image classification comparison system ready for Google Colab!**\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SVM_vs_CNN_Image_Classification_Comparison_with_Results.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}